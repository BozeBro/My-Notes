- 00:29 Got my tax documents for Roblox
- The conversations with the two teams in NYC went pretty nicely. I'm leaning towards the Cloud team atm.
	- I'll have to wait for next week for the Miami teams
- #journal I feel I want to learn something that is for me, but idk what that is rn. I feel I needed to have the goal in mind and then I can mindlessly work towards it during my free time. It's better than ruminating and doing nothing. Maybe #ChainReaction Scaling is the best thing to do rn, but I'm not too sure. But learning c++ is probably not the best for me as I am moving away from that direction it seems (Luckily).
- Got my grade for #15451 and i'm a bit disappointed in the score. I got the average but I feel I understand the material enough to actually get a better than that. (sigh)
- 09:45 In #15418, a bit late. Talking about latency and bandwidth and parallelizing that
	- Increasing throughput via *Pipelining*
		- Do many instructions back to back in a stream (overlapping) (like in Networking HTTP)
	- model for non-pipelined communication
		- $$T(n) = T_0+n/B$$
		- T(n) = transfer time
		- $T_0$ - start-up latency
		- n =bytes transffered in operation
		- B = Transfer rate (bandwidth of the link)
	- Another Comm model
		- Comm time = overhead + occupancy + network delay
			- overhead - pre work we need to do
			- occupancy - bottleneck time
			- network delay - all other delay
		- Communication cost = communication time - overlap
	- Summary: Structure code to have overlapping code (pipelining), minimize communication
	- DRAM - (Dynamic RAM (slow) )
	- [[15418 Lecture]] - shows how shared memory sort of works
	- reasons for communication: inherent vs. artificial communication
	- Reducing perimeter to area ratio in blocked parallelism can be good if only accessing neighbors
	- Artifactual communication: system be sending data that we aren't intending to send.
		- E.g. Cache lines, processor operating on a remote cache and need to move data to your cache, or your cache is already full
	- Four Cs
		- Cold Miss - access the cache/element for the first time
		- Capacity Miss - cache is full and need to evict to fit a member
		- Conflict Miss - cache element is different than element we are looking for.
		- Communication miss - another processor removed element in local cache
	- Sharing data increases arithmetic intensity (temporal locality)
		- co-locate tasks that operate on the same data
		- Reduces inherent communication
	- Spatial Locality
		- Blocked Data Layout - if blocking out a grid, put the memory in a 2d grid so the cache line will load up data from the 2d inner grid instead of random data.
		- Blocked layout is important for the exam possibly #15418/exam
	- Contention: many requests to a resource are made within the same time (hot spot)
		- A root has many children, and the children try updating the root (Flat tree structure)
		- Distributed work queue can also reduce contention. You get work from your own work queue.
- 14:58 In #Writing now
- #15451/Lecture Learning about "Fingerprinting"
	- Hash a number to a smaller number that can be compared in O(1) time which is good.
	- Error probability of comparison where $x\neq y$
	- Key points:
		- $\pi(2klg(k)) \geq k$  where \pi(n) is the count of primes in range [1, n]
	- $$P\left(x\neq q\land h_p(x) = h_p(y)\right) \leq \frac{n}{\pi(M)}$$
	- Methods to decrease odds of wrong equal.
		- repeat generating a prime and assert that all times generating a prime is the same
			- Or want $$\left(\frac{N}{\pi(N)}\right)^R \leq \delta$$ where R is the number of repititons
		- Choose a bigger M or $M = 2 * sN*lg(sN)$ where $s=\frac{1}{\delta}$
		- Representation for M is $\lg(M)$ bits
	- #Karp-Rabin Algorithm - Using hashes to match pattern with substrings of text.
		- Idea is use a rolling hash, and say yes when hashes are equal (requires a big prime p)
		- Error probability $\delta$ when p has $O(log(1/\delta +log m + log n)$ bits
		- length of text is M, and length of the pattern is n, where n < M.
			- Remember, when comparing hashes, we care about the length of pattern for N (thus N = n)
			- do $O(m)$ comparisons, each with error $1/s$ so $s=100m$ creates 1/100 error
			- $$M=2\cdot sNlg\left(sN\right) = 200mnlg(mn)\implies log(m)+log(n)$$ bits of storage
			- if s = $$m/\delta\implies M = \frac{2}{\delta}mnlg(\frac{mn}{\delta})\implies O(\lg(1/\delta ) + lg(m)+lg(n))$$
- #15418/Lecture5 Parallel Programming basics
	- #Parallel-models
		- shared address space
			- Communications is unstructured. Natural but can be inefficient.
		- message passing
			- structure all communication as messages.
			- harder to write first correct program than shared, but helps to write scalable programs.
		- Data parallel
			- structure computation as map over a collection
			- shared addr space to load inputs/store results, hard to communicate between iterations of map (independent processing of iterations)
			- usually this is encouraged.
		- Now: shared address space programming in multi-core node, message passing between nodes.
- 19:03 in #15330/Lecture
	- TO?  need to figure out how to write little endian code, and its reprsentation normal and in assembly.
		- How you see char* is always in big endian form. But the little endian form is always going to be in reverse.
	- Shellcode injection - injects launches a shell
	- Maybe install [gef](https://github.com/hugsy/gef)
	- Nop Slides - 0x90 in x86 is a nop, just increments the pc, but allows for different offsets to work out.
- #15330/tips - know your environment
	- xor a value with itself to get the null character
- #15330/Lecture - Exploiting format Strings in C
	- format string takes variable number of arguments and need to figure where those arguments are at runtime
	- Control Flow Hijacking:
	- DEP - Data Execution Prevention / No Execute
-
-